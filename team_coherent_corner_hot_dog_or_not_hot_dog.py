# -*- coding: utf-8 -*-
"""Team Coherent Corner: Hot Dog or Not Hot Dog

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zboHjJ4hRASo3uHNzH1TG_HtVZBm5rdr

#### Copyright 2019 Google LLC.
"""

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""# Hot Dog or Not Hot Dog

There are very few more important questions in life than "[Hot dog or not hot dog?](https://www.youtube.com/watch?v=ACmydtFDTGs)". For this challenge you will be tasked with creating a machine learning model that can take an input image and determine if the image is of a hot dog or not a hot dog.

Train your model with the [Kaggle Hot Dog/Not Hot Dog](https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog/data) data set. Feel free to [do some background research](https://medium.com/@timanglade/how-hbos-silicon-valley-built-not-hotdog-with-mobile-tensorflow-keras-react-native-ef03260747f3) on the topic.

We have looked a regression, classification, and clustering models. We have used the Scikit Learn, TensorFlow, and Keras toolkits. Feel free to use the model and toolkit that you feel is the most appropriate.

#Team members: Nicole, Maya, and Regina
![Snapchat Hot Dog](https://img.buzzfeed.com/buzzfeed-static/static/2017-07/11/14/asset/buzzfeed-prod-fastlane-02/anigif_sub-buzz-13445-1499796185-8.gif)
"""

# Open zip file
import zipfile
zip_ref = zipfile.ZipFile('hot-dog-not-hot-dog.zip', 'r')
zip_ref.extractall('./')
zip_ref.close()

import os
from PIL import Image, ImageOps
import numpy as np
import pandas as pd 

# Open images, process them, and add to dataframe
def load_images(directory):
  image_list = []
  image_df = pd.DataFrame()

  for filename in os.listdir(directory): 
    image_path = os.path.join(directory,filename)
    image = Image.open(image_path).convert('L') # convert to grey
    
    #padding on the image
    original_size = image.size
    padded_size = max(original_size)
    delta_w = padded_size - original_size[0]
    delta_h = padded_size - original_size[1]
    padding = (delta_w//2, delta_h//2, 
               delta_w-(delta_w//2), delta_h-(delta_h//2))
    padded_image = ImageOps.expand(image, padding, 255)
    
    #resize image
    resized_image = padded_image.resize((100,100), Image.ANTIALIAS)
    
    #flatten image
    flat_image = pd.Series(np.ravel(resized_image))
    
    #add flattened image to list
    image_list.append(flat_image)
  
  image_df = pd.DataFrame(image_list)
  
  return image_df

# Set up train and test dataframes
train_hot_dogs = load_images("./train/hot_dog")
train_hot_dogs['TARGET'] = 1
train_not_dogs = load_images("./train/not_hot_dog")
train_not_dogs['TARGET'] = 0
test_hot_dogs = load_images("./test/hot_dog")
test_hot_dogs['TARGET'] = 1
test_not_dogs = load_images("./test/not_hot_dog")
test_not_dogs['TARGET'] = 0
train_df = pd.concat([train_hot_dogs, train_not_dogs])
test_df = pd.concat([test_hot_dogs, test_not_dogs])

# Data preparation
# Scale training
train_df[train_df.columns.values[0:-1]] = train_df[train_df.columns.values[0:-1]]/255.0

# Scale testing
test_df[test_df.columns.values[0:-1]] = test_df[test_df.columns.values[0:-1]]/255.0
test_df.head()

# Create feature columns
from tensorflow.feature_column import numeric_column

pixel_features = []

for column_name in train_df.columns[0:-1]:
  pixel_features.append(numeric_column(str(column_name).strip()))

len(pixel_features)
#pixel_features

# Create DNN
from tensorflow.estimator import DNNClassifier
classifier = DNNClassifier(feature_columns = pixel_features,
                           hidden_units = [392, 196], n_classes = 2)

# Training model
import tensorflow as tf
from tensorflow.data import Dataset

def training_input():
  features = {}
  for i in range(len(pixel_features)):
#     column_name = str(i)
    features[str(i).strip()] = train_df[i]
  
  labels = train_df['TARGET']

  training_ds = Dataset.from_tensor_slices((features, labels))
  training_ds = training_ds.shuffle(buffer_size=10000)
  training_ds = training_ds.batch(100)
  training_ds = training_ds.repeat(5)
  return training_ds

classifier.train(training_input)

# Test and predictions
def testing_input():
  features = {}
  for i in range(len(pixel_features)):
    features[str(i).strip()] = test_df[i]
  return Dataset.from_tensor_slices((features)).batch(1)

predictions = list(classifier.predict(testing_input))

# Testing predictions
test_df.iloc[0]['TARGET']

# 1 = hot dog
# 0 = not dog

# Plot image
import matplotlib.pyplot as plt

image_to_view = 0

plt.imshow(
  test_df[test_df.columns.values[0:-1]].iloc[image_to_view].values.reshape(100,100),
  cmap='gray')
plt.show()

test_df

predicted_classes = [p['class_ids'][0] for p in predictions]
predicted_classes

from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score

print("Accuracy:", accuracy_score(test_df['TARGET'], predicted_classes))
print("F1:", f1_score(test_df['TARGET'], predicted_classes))